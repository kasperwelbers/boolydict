% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/search_query.r
\name{search_query}
\alias{search_query}
\title{Match text to queries using a Lucene-like search query}
\usage{
search_query(
  df,
  queries,
  text = "text",
  context = NULL,
  index = NULL,
  mode = c("hits", "terms"),
  keep_longest = TRUE,
  as_ascii = F
)
}
\arguments{
\item{df}{A data.frame (or tibble, data.table, whatever)}

\item{queries}{A character string that is a query. See details for available query operators and modifiers. Can be multiple queries (as a vector).}

\item{text}{The column in df with the text to query. Defaults to 'text'. (see details if you want to use multiple columns in a query)}

\item{context}{Optionally, a column in df with context ids. If used, texts across rows are grouped together so that you can perform Boolean queries across rows.
The primary use case is if texts are tokens/words, such as produced by tidytext, udpipe or spacyr.}

\item{index}{Optionally, a column in df with indices for texts within a context. In particular, if texts are tokens, these are the token positions. This is only
relevant if not all tokens are used, and we therefore don't know these positions. The indices then need to be provided to correctly match multitoken strings and proximity queries.}

\item{mode}{There are two modes: "hits" and "terms". The "hits" mode prioritizes finding full and unique matches.,
which is recommended for counting how often a query occurs. However, this also means that some tokens
for which the query is satisfied might not assigned a hit_id. The "terms" mode, instead, prioritizes
finding all tokens/terms.}

\item{keep_longest}{If TRUE, then overlapping in case of overlapping queries strings in unique_hits mode, the query with the most separate terms is kept. For example, in the text "mr. Bob Smith", the query [smith OR "bob smith"] would match "Bob" and "Smith". If keep_longest is FALSE, the match that is used is determined by the order in the query itself. The same query would then match only "Smith".}

\item{as_ascii}{if TRUE, perform search in ascii. Can be useful if you know text contains things like accents, and these are either used inconsistently or you simply
can't be bothered to type them in your queries.}
}
\value{
A data.table with matches, specifying the index of the data (data_index), the index of the query (query_index) and a unique hit_id.
}
\description{
This function matches a vector of queries to a data.frame with a text column. The output is intentionally very bare bones, so that the function can be used as a
basis for more convenient applications, such as query_subset, query_join and query_aggregate.
}
\details{
Brief summary of the query language

The following operators and modifiers are supported:
\itemize{
   \item{The standaard Boolean operators: AND, OR and NOT. As a shorthand, an empty space can be used as an OR statement, so that "this that those" means "this OR that OR those". NOT statements stricly mean AND NOT, so should only be used between terms. If you want to find \emph{everything except} certain terms, you can use * (wildcard for \emph{anything}) like this: "* NOT (this that those)".}
   \item{For complex queries parentheses can (and should) be used. e.g. '(spam AND eggs) NOT (fish and (chips OR albatros))}
   \item{Wildcards ? and *. The questionmark can be used to match 1 unknown character or no character at all, e.g. "?at" would find "cat", "hat" and "at". The asterisk can be used to match any number of unknown characters. Both the asterisk and questionmark can be used at the start, end and within a term.}
   \item{Multitoken strings, or exact strings, can be specified using quotes. e.g. "united states"}
   \item{tokens within a given token distance can be found using quotes plus tilde and a number specifiying the token distance. e.g. "climate chang*"~10}
   \item{Alternatively, angle brackets (<>) can be used instead of quotes, which also enables nesting exact strings in proximity/window search}
   \item{Queries are not case sensitive, but can be made so by adding the ~s flag. e.g. COP~s only finds "COP" in uppercase. The ~s flag can also be used on parentheses or quotes to make all terms within case sensitive, and this can be combined with the token proximity flag. e.g. "Marco Polo"~s10}
   \item{The ~g (ghost) flag can be used to mark a term (or all terms within parentheses/quotes) as a ghost term (this is primarily usefull if texts are tokens grouped together in a context). This has two effects. Firstly, features that match the query term will not be in the results. This is usefull if a certain term is important for getting reliable search results, but not conceptually relevant. Secondly, ghost terms can be used multiple times, in different query hits (only relevant in unique_hits mode). For example, in the text "A B C", the query 'A~g AND (B C)' will return both B and C as separate hit, whereas 'A AND (B C)' will return A and B as a single hit.}
   \item{A code label can be included at the beginning of a query, followed by a # to start the query (label# query). Note that to search for a hashtag symbol, you need to escape it with \ (double \\ in R character vector)}
   \item{Aside from the feature column (specified with the feature argument) a query can include any column in the token data. To manually select a column, use 'columnname: ' at the start of a query or nested query (i.e. between parentheses or quotes). See examples for clarification.}
   }
}
\examples{

# the simplest case is to search in a vector of texts
text = c("some example text", "some more text")
search_query(text, queries = c("some", "<example text>"))

# in the results, the query_index tells which query was matched, data_index tells
# the index of the text, and hit_id gives an id for each match (unique within query_index)

# we can also specify a context in which text occurs, in which case Boolean operators work across rows. This
# for instance means that we can also query specific tokens.

d = data.frame(token = c("some","example","text", "some", "more", "text"),
               doc_id = c(1,1,1,2,2,2))
search_query(d, text='token', context='doc_id', queries="example AND text")

# note that the data_index now points to the specific tokens that are matched, and
# that they have the same hit_id because it's the same match.


\donttest{

## query language examples

text = c('A B C', 'D E F. G H I', 'A D', 'GGG')

## single term
search_query(text, 'A')

search_query(text, 'G*')    ## wildcard *
search_query(text, '*G')    ## wildcard *
search_query(text, 'G*G')   ## wildcard *

search_query(text, 'G?G')   ## wildcard ?
search_query(text, 'G?')    ## wildcard ? (no hits)

## boolean
search_query(text, 'A AND B')
search_query(text, 'A AND D')
search_query(text, 'A AND (B OR D)')

search_query(text, 'A NOT B')
search_query(text, 'A NOT (B OR D)')


## sequence search (adjacent words)
search_query(text, '"A B"')
search_query(text, '"A C"') ## no hit, because not adjacent

search_query(text, '"A (B OR D)"') ## can contain nested OR
## cannot contain nested AND or NOT!!

search_query(text, '<A B>') ## can also use <> instead of "".

## proximity search (using ~ flag)
search_query(text, '"A C"~5') ## A AND C within a 5 word window
search_query(text, '"A C"~1') ## no hit, because A and C more than 1 word apart

search_query(text, '"A (B OR D)"~5') ## can contain nested OR
search_query(text, '"A <B C>"~5')    ## can contain nested sequence (must use <>)
search_query(text, '<A <B C>>~5')    ## <> is always OK, but cannot nest "" in ""
## cannot contain nested AND or NOT!!

## case sensitive search (~s flag)
search_query(text, 'g')     ## normally case insensitive
search_query(text, 'g~s')   ## use ~s flag to make term case sensitive

search_query(text, '(a OR g)~s')   ## use ~s flag on everything between parentheses
search_query(text, '(a OR G)~s')

search_query(text, '"a b"~s')   ## use ~s flag on everything between quotes
search_query(text, '"A B"~s')   ## use ~s flag on everything between quotes

## ghost terms (~g flag)
d = data.frame(text = c('A','B'), group=c(1,1))
search_query(d, context='group', 'A AND B~g')    ## ghost term (~g) has to occur, but is not returned
search_query(text, 'A AND Q~g')    ## no hit

# (can also be used on parentheses/quotes/anglebrackets for all nested terms)


## "unique_hits" versus "features" mode
text = 'A A B'

search_query(text, 'A AND B') ## in "unique_hits" (default), only match full queries
# (B is not repeated to find a second match of A AND B)

search_query(text, 'A AND B', mode = 'features') ## in "features", match any match
# (note that hit_id in features mode is irrelevant)

# ghost terms (used for conditions) can be repeated
search_query(text, 'A AND B~g')

}
}
